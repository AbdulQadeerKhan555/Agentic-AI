{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuhFH8OeTFtz9H96gha8YR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdulQadeerKhan555/Agentic-AI/blob/main/0_Hello_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installation of openai agents**"
      ],
      "metadata": {
        "id": "SsIMbWxTitVj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKLOCNIMrdrw"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import asyncronous function**"
      ],
      "metadata": {
        "id": "wdeQLoUci6wP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "Cz_MkT4Ui2U8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import main things**"
      ],
      "metadata": {
        "id": "yvnP29dVjY_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel, set_tracing_disabled"
      ],
      "metadata": {
        "id": "wDmgOQYLjgyy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**API Key setting**"
      ],
      "metadata": {
        "id": "O_Gy0rLNj9sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "bDvCRRK_kCYf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Client Setup for connecting to Gemini**"
      ],
      "metadata": {
        "id": "WZp8TzgzlGYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To disable tracing\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "# Create a client/ Which LLM service?\n",
        "external_client: AsyncOpenAI = AsyncOpenAI(\n",
        "    api_key = gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "# Which LLM Model?\n",
        "model_of_llm: OpenAIChatCompletionsModel = OpenAIChatCompletionsModel(\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    openai_client=external_client\n",
        ")"
      ],
      "metadata": {
        "id": "xV-o63DqlR27"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Running Agent Synchronously**"
      ],
      "metadata": {
        "id": "bhUy9cZOm9So"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner\n",
        "\n",
        "math_agent : Agent = Agent(\n",
        "    name = \"MathAgent\",\n",
        "    instructions = \"You are a math assistant\",\n",
        "    model = model_of_llm\n",
        ")\n",
        "result: Runner = Runner.run_sync(\n",
        "    math_agent, \"Why we learn math for AI agents. answer in 3 lines\"\n",
        ")\n",
        "print(\"\\nCALLING AGENT\\n\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "id": "N-LQUxCGnHlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running Agent Asynchronously**"
      ],
      "metadata": {
        "id": "rItaPPk6upSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner\n",
        "\n",
        "async def main():\n",
        "  result: Runner =await Runner.run(\n",
        "    math_agent, \"Tell me about recursion in programming.\" )\n",
        "  print(result.final_output)\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "Ge-fgCm_uwzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recipe Bot**"
      ],
      "metadata": {
        "id": "k_8th6eDxle1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_tracing_disabled(disabled=True)\n",
        "# external client setting/ which llm service\n",
        "external_client: AsyncOpenAI = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "# Which llm model\n",
        "model_of_llm: OpenAIChatCompletionsModel = OpenAIChatCompletionsModel(\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    openai_client=external_client\n",
        ")\n",
        "# Creating agent\n",
        "def main():\n",
        "  agent: Agent = Agent(\n",
        "      name = \"Recipe Bot\",\n",
        "      instructions = \"\"\"You are a recipe agent. A user will give you few ingridents that\n",
        "       are available at home. you have to seggest a simple and quick receipe from those things.\n",
        "       keep the recipe short, step by step and easy to cook for beginner.\"\"\" ,\n",
        "      model = model_of_llm\n",
        "  )\n",
        "  print(\"What can i cook today? \\n\")\n",
        "  ingridient = \"eggs, tomatos, onions and bread\"\n",
        "  result: Runner = Runner.run_sync(agent,f\"I have these ingridients {ingridient} at home. what can i cook\")\n",
        "  print(result.final_output)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "InZwpSI-xkeU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
